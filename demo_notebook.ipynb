{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595472957419",
   "display_name": "Python 3.7.5 64-bit ('NLP': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code to parse the ielex data and build a dataset from an ancestral language and its descendants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "dataset_path = 'data/ielex.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_norse_iso_code = 'non'\n",
    "# non: Old Norse, isl: Icelandic, fao: Faroese, swe: Swedish, dan: Danish, nor: Norwegian\n",
    "nordic_iso_codes = {'isl', 'fao', 'swe', 'dan', 'nor'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "latin_iso_code = 'lat'\n",
    "# lat: Latin, spa: Spanish, por: Portuguese, fra: French, ita: Italian\n",
    "romance_iso_codes = {'spa', 'por', 'fra', 'ita'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_subfamily(parent_lang_iso, daughter_iso_codes):\n",
    "    '''\n",
    "    parent_lang_iso: str, the iso code of the common ancestral language\n",
    "    daughter_iso_codes: a set of str, the iso codes of the daughter languages of that parent\n",
    "\n",
    "    returns a dictionary of the form {lang_iso_code: {global_id: (parent_line, daughter_line)}}, \\\n",
    "        which maps a daughter lang's iso code to a dict containing all cognate pairs in the dataset\n",
    "        between the ancestor and that daughter lang.\n",
    "    '''\n",
    "\n",
    "    with open(dataset_path) as f:\n",
    "        reader = csv.reader(f, delimiter='\\t') # the file is a tsv (tab separated values)\n",
    "        next(reader) # burn the header row\n",
    "\n",
    "        # I assume that any given language, parent or daughter, only has one word per particular cognate class. Running code on ielex.tsv, at least, it seems this assumption is correct.\n",
    "        parent_dict = {} # cognates in the parent lang. {global_id: {cognate class: line}}\n",
    "        daughter_dict = {} # cognates in the daughter langs. {global_id: {cognate class: {lang_iso_code: line}}}\n",
    "\n",
    "        # go through the file once and populate the above dicts\n",
    "        for line in reader:\n",
    "            # these are all the different entires a line could have\n",
    "            language = line[0]\n",
    "            iso_code = line[1]\n",
    "            gloss = line[2]\n",
    "            global_id = line[3]\n",
    "            local_id = line[4]\n",
    "            transcription = line[5]\n",
    "            cognate_class = line[6]\n",
    "            tokens = line[7]\n",
    "            # notes = line[8]\n",
    "\n",
    "            if iso_code == parent_lang_iso:\n",
    "                if global_id not in parent_dict:\n",
    "                    parent_dict[global_id] = {}\n",
    "                if cognate_class not in parent_dict[global_id]:\n",
    "                    parent_dict[global_id][cognate_class] = line\n",
    "            elif iso_code in daughter_iso_codes:\n",
    "                if global_id not in daughter_dict:\n",
    "                    daughter_dict[global_id] = {}\n",
    "                if cognate_class not in daughter_dict[global_id]:\n",
    "                    daughter_dict[global_id][cognate_class] = {}\n",
    "                daughter_dict[global_id][cognate_class][iso_code] = line\n",
    "\n",
    "    print('identified', len(parent_dict), 'parent cognates')\n",
    "    print('identified', len(daughter_dict), 'daughter cognates')\n",
    "\n",
    "    cognate_pair_dicts = {iso_code: {} for iso_code in daughter_iso_codes} # map a language to a dictionary with particular cognates {lang_iso_code: {global_id: (parent_line, daughter_line)}}\n",
    "\n",
    "    # identify cognates where they exist both in the parent lang and at least one daughter lang\n",
    "    for global_id in parent_dict:\n",
    "        if global_id in daughter_dict:\n",
    "            for cognate_class in parent_dict[global_id]:\n",
    "                if cognate_class in daughter_dict[global_id]:\n",
    "                    parent_line = parent_dict[global_id][cognate_class]\n",
    "\n",
    "                    for lang_iso_code in daughter_dict[global_id][cognate_class]:\n",
    "                        daughter_line = daughter_dict[global_id][cognate_class][lang_iso_code]\n",
    "                        cognate_pair_dicts[lang_iso_code][global_id] = (parent_line, daughter_line)\n",
    "    \n",
    "    return cognate_pair_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "identified 202 parent cognates\nidentified 203 daughter cognates\nfra : 135\nita : 147\npor : 131\nspa : 134\n"
    }
   ],
   "source": [
    "romance_cognate_pair_dicts = filter_subfamily(latin_iso_code, romance_iso_codes)\n",
    "\n",
    "# for each daughter lang, count the number of attested cognates. We'll pick the top two, training the model on parent -> daughter_1 and benchmark performance on parent -> daughter_2\n",
    "for lang in romance_cognate_pair_dicts:\n",
    "    print(lang, ':', len(romance_cognate_pair_dicts[lang]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(['LATIN', 'lat', 'come', '1446', 'come', 'weˈniːre', 'come:B', 'w e ˈn iː r e', ''], ['ITALIAN', 'ita', 'come', '1446', 'come', 'venire', 'come:B', 'v e n i r e', ''])\n(['LATIN', 'lat', 'snow', '784', 'snow', 'niks', 'snow:B', 'n i k s', ''], ['ITALIAN', 'ita', 'snow', '784', 'snow', 'neve', 'snow:B', 'n e v e', ''])\n(['LATIN', 'lat', 'sing', '1261', 'sing', 'ˈkanere', 'sing:D', 'ˈk a n e r e', ''], ['ITALIAN', 'ita', 'sing', '1261', 'sing', 'kantare', 'sing:D', 'k a n t a r e', ''])\n(['LATIN', 'lat', 'tail', '1220', 'tail', 'ˈkau̯da', 'tail:F', 'ˈk a u̯ d a', ''], ['ITALIAN', 'ita', 'tail', '1220', 'tail', 'koda', 'tail:F', 'k o d a', ''])\n(['LATIN', 'lat', 'die', '1494', 'die', 'ˈmoriː', 'die:A', 'ˈm o r iː', ''], ['ITALIAN', 'ita', 'die', '1494', 'die', 'morire', 'die:A', 'm o r i r e', ''])\n(['LATIN', 'lat', 'cold', '1287', 'cold', 'ˈfriːgidus', 'cold:E', 'ˈf r iː g i d u s', ''], ['ITALIAN', 'ita', 'cold', '1287', 'cold', 'freddo', 'cold:E', 'f r e dd o', ''])\n(['LATIN', 'lat', 'name', '1405', 'name', 'ˈnoːmen', 'name:A', 'ˈn oː m e n', ''], ['ITALIAN', 'ita', 'name', '1405', 'name', 'nome', 'name:A', 'n o m e', ''])\n(['LATIN', 'lat', 'water', '948', 'water', 'ˈakʷa', 'water:E', 'ˈa kʷ a', ''], ['ITALIAN', 'ita', 'water', '948', 'water', 'akkwa', 'water:E', 'a kk w a', ''])\n(['LATIN', 'lat', 'what', '1236', 'what', 'kʷid', 'what:A', 'kʷ i d', ''], ['ITALIAN', 'ita', 'what', '1236', 'what', 'ke', 'what:A', 'k e', ''])\n(['LATIN', 'lat', 'kill', '1417', 'kill', 'oˈkːiːdere', 'kill:O', 'o ˈkː iː d e r e', ''], ['ITALIAN', 'ita', 'kill', '1417', 'kill', 'uttʃidere', 'kill:O', 'u tt ʃ i d e r e', ''])\n"
    }
   ],
   "source": [
    "# sample some data to examine\n",
    "for k in list(romance_cognate_pair_dicts['ita'])[:10]:\n",
    "    print(romance_cognate_pair_dicts['ita'][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "identified 207 parent cognates\nidentified 207 daughter cognates\nnor : 199\nisl : 205\nswe : 195\nfao : 203\ndan : 194\n"
    }
   ],
   "source": [
    "nordic_cognate_pair_dicts = filter_subfamily(old_norse_iso_code, nordic_iso_codes)\n",
    "\n",
    "for lang in nordic_cognate_pair_dicts:\n",
    "    print(lang, ':', len(nordic_cognate_pair_dicts[lang]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(['OLD_NORSE', 'non', 'sharp', '1396', 'sharp', 'skarpr', 'sharp:B', 's k a r p r', ''], ['SWEDISH', 'swe', 'sharp', '1396', 'sharp', 'skarp', 'sharp:B', 's k a r p', ''])\n(['OLD_NORSE', 'non', 'come', '1446', 'come', 'ˈkoma', 'come:B', 'ˈk o m a', ''], ['SWEDISH', 'swe', 'come', '1446', 'come', 'ˈkɔ̀mːa', 'come:B', 'ˈk ɔ̀ mː a', ''])\n(['OLD_NORSE', 'non', 'yellow', '1424', 'yellow', 'ɡulr', 'yellow:A', 'ɡ u l r', ''], ['SWEDISH', 'swe', 'yellow', '1424', 'yellow', 'ɡʉːl', 'yellow:A', 'ɡ ʉː l', ''])\n(['OLD_NORSE', 'non', 'snow', '784', 'snow', 'snjoːr', 'snow:B', 's n j oː r', ''], ['SWEDISH', 'swe', 'snow', '784', 'snow', 'snøː', 'snow:B', 's n øː', ''])\n(['OLD_NORSE', 'non', 'sing', '1261', 'sing', 'ˈsynɣva', 'sing:B', 'ˈs y n ɣ v a', ''], ['SWEDISH', 'swe', 'sing', '1261', 'sing', 'ˈɧɵ̀ŋːa', 'sing:B', 'ˈɧ ɵ̀ ŋː a', ''])\n(['OLD_NORSE', 'non', 'tail', '1220', 'tail', 'stertr', 'tail:B', 's t e r t r', ''], ['SWEDISH', 'swe', 'tail', '1220', 'tail', 'ɧæʈː', 'tail:B', 'ɧ æ ʈː', ''])\n(['OLD_NORSE', 'non', 'die', '1494', 'die', 'ˈdɛyja', 'die:B', 'ˈd ɛ y j a', ''], ['SWEDISH', 'swe', 'die', '1494', 'die', 'dø:', 'die:B', 'd ø:', ''])\n(['OLD_NORSE', 'non', 'cold', '1287', 'cold', 'kaldr', 'cold:B', 'k a l d r', ''], ['SWEDISH', 'swe', 'cold', '1287', 'cold', 'kalː', 'cold:B', 'k a lː', ''])\n(['OLD_NORSE', 'non', 'name', '1405', 'name', 'nafn', 'name:A', 'n a f n', ''], ['SWEDISH', 'swe', 'name', '1405', 'name', 'namn', 'name:A', 'n a m n', ''])\n(['OLD_NORSE', 'non', 'stick', '1295', 'stick', 'stavr', 'stick:D', 's t a v r', ''], ['SWEDISH', 'swe', 'stick', '1295', 'stick', 'stɑːv', 'stick:D', 's t ɑː v', ''])\n"
    }
   ],
   "source": [
    "for k in list(nordic_cognate_pair_dicts['swe'])[:10]:\n",
    "    print(nordic_cognate_pair_dicts['swe'][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the custom dataset to a file\n",
    "def save_dataset(cognate_pair_dict, output_dir=None):\n",
    "    '''\n",
    "    Saves a cognate pair dict for a particular daughter language as two .tsv files, \\\n",
    "        one containing the parent lang's cognates, the other the daughter's.\n",
    "\n",
    "    cognate_pair_dict: the cognate pair dictionary for the daughter language, formatted like one of the dictionaries in the output of filter_subfamily()\n",
    "    output_dir: directory the files will be saved in, under /data/. Default folder name is 'ParentLang-DaughterLang Cognates'\n",
    "    '''\n",
    "\n",
    "    # we extract an arbitrary line from the dictionary to obtain the parent and daughter iso codes\n",
    "    parent_line, daughter_line = next(iter(cognate_pair_dict.values())) # popping from an iterator is best way of doing this: it uses the least space since it doesn't load the whole dictionary\n",
    "\n",
    "    if output_dir is None: # generate default directory name\n",
    "        parent_language, daughter_language = parent_line[0], daughter_line[0]\n",
    "        output_dir = parent_language + '-' + daughter_language + ' Cognates'\n",
    "        output_dir = output_dir.title() # format to make the folder easier to read\n",
    "    \n",
    "    output_dir = os.path.join('data', output_dir)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "    \n",
    "    parent_iso, daughter_iso = parent_line[1], daughter_line[1]\n",
    "    parent_file_path = os.path.join(output_dir, parent_iso + '.tsv')\n",
    "    daughter_file_path = os.path.join(output_dir, daughter_iso + '.tsv')\n",
    "\n",
    "    with open(parent_file_path, 'w') as f_p, open(daughter_file_path, 'w') as f_d:\n",
    "        writer_p = csv.writer(f_p, delimiter='\\t')\n",
    "        writer_d = csv.writer(f_d, delimiter='\\t')\n",
    "\n",
    "        header = ['language', 'iso_code', 'gloss', 'global_id', \n",
    "            'local_id', 'transcription', 'cognate_class', 'tokens', 'notes']\n",
    "        writer_p.writerow(header)\n",
    "        writer_d.writerow(header)\n",
    "\n",
    "        for k in cognate_pair_dict.keys():\n",
    "            parent_line, daughter_line = cognate_pair_dict[k]\n",
    "            writer_p.writerow(parent_line)\n",
    "            writer_d.writerow(daughter_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'Old_Norse-Icelandic Cognates'\n",
    "\n",
    "save_dataset(nordic_cognate_pair_dicts['isl'], file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}