import pickle
import re
import sys
from argparse import ArgumentParser
from dataclasses import asdict, dataclass
from functools import lru_cache
from typing import List, Tuple

import pandas as pd
import streamlit as st
from cltk.phonology.old_english.orthophonology import \
    OldEnglishOrthophonology as oe
from cltk.phonology.old_norse.orthophonology import on
from lingpy.sequence.sound_classes import ipa2tokens

from pypheature.nphthong import Nphthong
from pypheature.process import FeatureProcessor
from sound_law.utils import run_section, run_with_argument
from xib.aligned_corpus.transcriber import RuleBasedTranscriber


@lru_cache(maxsize=None)
def PGmc_ipa_trans(word: str) -> str:  # only for latin-transliterated Gothic and Greek without diacritics
    # NOTE(j_luo) Based on Frederik's code, with minor modifications.
    word = word.lower()
    word = word.replace('‚ÇÇ', '')
    # vowels
    word = re.sub(r"ƒì", "eÀê", word)
    word = re.sub(r"≈ç", "oÀê", word)
    word = re.sub(r"ƒÅ", "aÀê", word)
    word = re.sub(r"ƒ´", "iÀê", word)
    word = re.sub(r"≈´", "uÀê", word)

    word = re.sub(r"√¥", "oÀêÀê", word)
    word = re.sub(r"√™", "eÀêÀê", word)

    word = re.sub(r'«≠', 'oÃÉÀê', word)
    word = re.sub(r'ƒÖ', 'aÃÉ', word)
    word = re.sub(r'ƒØÃÑ', 'ƒ©Àê', word)

    # consonants
    word = re.sub(r"h", "x", word)
    word = re.sub(r"f", "f", word)
    word = re.sub(r"xw", "x ∑", word)
    word = re.sub(r"kw", "k ∑", word)
    word = re.sub(r"√æ", "Œ∏", word)

    # alternations
    word = re.sub(r"d", "√∞", word)
    word = re.sub(r"n√∞", "nd", word)
    word = re.sub(r"l√∞", "ld", word)
    word = re.sub(r"z√∞", "zd", word)
    word = re.sub(r"^√∞", "d", word)

    word = re.sub(r"b", "Œ≤", word)
    word = re.sub(r"^Œ≤", "b", word)

    word = re.sub(r"g", "…°", word)
    word = re.sub(r"…°w", "…° ∑", word)

    word = re.sub(r"nk", "≈ãk", word)
    word = re.sub(r"ng", "≈ã…°", word)
    word = re.sub(r"ng", "≈ã…°", word)

    return word


got_map = {
    'êå∞': 'a',
    'êå±': 'b',
    'êå≤': 'g',
    'êå≥': 'd',
    'êå¥': 'e',
    'êåµ': 'q',
    'êå∂': 'z',
    'êå∑': 'h',
    'êå∏': '√æ',
    'êåπ': 'i',
    'êå∫': 'k',
    'êåª': 'l',
    'êåº': 'm',
    'êåΩ': 'n',
    'êåæ': 'j',
    'êåø': 'u',
    'êçÄ': 'p',
    'êçÇ': 'r',
    'êçÉ': 's',
    'êçÑ': 't',
    'êçÖ': 'w',
    'êçÜ': 'f',
    'êçá': 'x',
    'êçà': '∆ï',
    'êçâ': 'o',
}


def got_transliterate(s: str) -> str:
    ret = ''
    for c in s:
        ret += got_map[c]
    return ret


def i2t(s):
    tokens = ipa2tokens(s, merge_vowels=True, merge_geminates=True)
    ret = list()
    for token in tokens:
        l = len(token)
        # NOTE(j_luo) Merge geminates into one segment.
        if l % 2 == 0 and token[:l // 2] == token[l // 2:]:
            ret.append(token[:l // 2] + 'Àê')
        else:
            ret.append(token)
    return ret


def show_all_segs(series):
    segs = set()
    for tokens in series:
        segs.update(tokens)
    out = ', '.join(sorted(segs))
    if st._is_running_with_streamlit:
        st.write(out)
        st.write(f'Number of sounds: {len(segs)}')
    else:
        print(out)
        print(f'Number of sounds: {len(segs)}')


to_break_got = {
    'tÕ°s': ['t', 's'],
    '…õÀêa': ['…õÀê', 'a']
}
to_break_pgm = {
    'eÀêa': ['eÀê', 'a'],
    'oÀêa': ['oÀê', 'a']
}
to_break = {
    'got': to_break_got,
    'pgm': to_break_pgm,
    'ang': dict(),
    'non': dict()
}

got2ipa_map = {
    'g': '…°',
    "ah": "aÀêh",
    "aih": "…õh",
    "air": "…õr",
    "ai": "…õÀê",
    "auh": "…îh",
    "aur": "…îr",
    "au": "…îÀê",
    "ei": "iÀê",
    "e": "eÀê",
    "o": "oÀê",
    "ur": "uÀêr",
    "uh": "uÀêh",
    "ab": "aŒ≤",
    "…õb": "…õŒ≤",
    "…îb": "…îŒ≤",
    "ib": "iŒ≤",
    "eb": "eŒ≤",
    "ob": "oŒ≤",
    "ub": "uŒ≤",
    "bd": "Œ≤d",
    "bn": "Œ≤n",
    "bm": "Œ≤m",
    "b…°": "Œ≤…°",
    "bl": "Œ≤l",
    "bj": "Œ≤j",
    "br": "Œ≤r",
    "bw": "Œ≤w",
    "bz": "Œ≤z",
    " Œ≤": " b",
    "ad": "a√∞",
    "…õd": "…õ√∞",
    "…îd": "…î√∞",
    "id": "i√∞",
    "ed": "e√∞",
    "od": "o√∞",
    "ud": "u√∞",
    "db": "√∞b",
    "dŒ≤": "√∞Œ≤",
    "dn": "√∞n",
    "dm": "√∞m",
    "d…°": "√∞…°",
    "dl": "√∞l",
    "dj": "√∞j",
    "dr": "√∞r",
    "dw": "√∞w",
    "dz": "√∞z",
    " √∞": " d",
    # "f": "…∏",
    "f": "f",
    "…°w": "…° ∑",
    "hw": "h ∑",
    "a…°": "a…£",
    "…õ…°": "…õ…£",
    "…î…°": "…î…£",
    "i…°": "i…£",
    "e…°": "e…£",
    "o…°": "o…£",
    "u…°": "u…£",
    "…°b": "…£b",
    "…°Œ≤": "…£Œ≤",
    "…°n": "…£n",
    "…°m": "…£m",
    "…°…°": "≈ã…°",
    "…°l": "…£l",
    "…°j": "…£j",
    "…°r": "…£r",
    "…°w": "…£w",
    "…°z": "…£z",
    "…°p": "xp",
    "…°t": "xt",
    "…°k": "≈ãk",
    "…°…∏": "x…∏",
    "…°h": "xh",
    "…°s": "xs",
    "…°√æ": "x√æ",
    "…°q": "xq",
    " …£": " …°",
    " x": " …°",
    "qw": "k ∑",
    "√æ": "Œ∏",
    '∆ï': 'h ∑',
    'q': 'k ∑'
}


def replace(s: str, repl_map: List[Tuple[str, str]]) -> str:
    for x, y in repl_map:
        s = s.replace(x, y)
    return s


def got_transcribe(s: str) -> str:
    return replace(s, got2ipa_map.items())


def break_false_complex(s: List[str], lang: str = None) -> List[str]:
    assert lang is not None
    ret = list()
    for seg in s:
        if seg in to_break[lang]:
            ret.extend(to_break[lang][seg])
        else:
            ret.append(seg)
    return ret


PDF = pd.DataFrame


@run_section('Loading data...', 'Loading done.')
def load_data(gem_pro_path: str, swadesh_gem_pro_path: str) -> Tuple[PDF, PDF]:
    # Get cognate data.
    gem_pro = pd.read_csv(gem_pro_path, sep='\t')
    # Get Swadesh list.
    swa = pd.read_csv(swadesh_gem_pro_path, sep='\t', header=None)
    return gem_pro, swa


@run_section('Removing any duplicates or words that do not have a unique reflex...',
             'Removal done.')
def remove_duplicate(gem_pro: PDF, swa: PDF) -> PDF:
    to_keep = set()
    for tokens in swa[2]:
        for token in tokens.split():
            to_keep.add(token.strip('*'))
    kept = gem_pro[gem_pro['gem-pro'].isin(to_keep)].reset_index(drop=True)
    desc = kept[kept['desc_lang'] == lang].reset_index(drop=True)
    dups = {k for k, v in desc['gem-pro'].value_counts().to_dict().items() if v > 1}
    desc = desc[~desc['gem-pro'].isin(dups)].reset_index(drop=True)
    return desc


if __name__ == "__main__":
    parser = ArgumentParser()
    st.title('Prepare RL dataset.')
    st.header('Specify the arguments first:')
    lang = run_with_argument('lang',
                             parser=parser,
                             default='',
                             msg='Daughter language.')
    out_dir = run_with_argument('out_dir',
                                parser=parser,
                                default='data/wikt',
                                msg='Output directory')
    gem_pro_path = run_with_argument('gem_pro_path',
                                     parser=parser,
                                     default='data/gem-pro.tsv',
                                     msg='Path to the Proto-Germanic cognate data extracted from Wiktionary.')
    swadesh_gem_pro_path = run_with_argument('swadesh_gem_pro_path',
                                             parser=parser,
                                             default='data/swadesh_gem_pro.tsv',
                                             msg='Path to the Proto-Germanic Swadesh list.')
    gem_pro, swa = load_data(gem_pro_path, swadesh_gem_pro_path)
    desc = remove_duplicate(gem_pro, swa)
    st.write(f'{len(desc)} entries in total')

    if lang == "got":
        ipa_col = 'got_ipa'
        form_col = 'latin'
        desc = desc.assign(**{form_col: desc['desc_form'].apply(got_transliterate)})
        desc = desc.assign(**{ipa_col: desc[form_col].apply(got_transcribe).apply(i2t)})
    elif lang == 'ang':
        ipa_col = 'ang_ipa'
        form_col = 'desc_form'
        # NOTE(j_luo) Use the simple `a` phoneme to conform to other transcribers.
        to_rectify = [('…ë', 'a'), ('g', '…°'), ('h', 'x'), ('h ∑', 'x ∑'), ('√ß', 'x')]

        desc[ipa_col] = desc[form_col].apply(lambda s: oe(
            s.strip('-').replace('ƒã', 'c').replace('ƒ°', 'g'))).apply(i2t).apply(lambda lst: [replace(x, to_rectify) for x in lst])
    elif lang == 'non':
        ipa_col = 'non_ipa'
        form_col = 'desc_form'
        to_rectify = [('g', '…°'), ('g ∑', '…° ∑'), ('h', 'x'), ('h ∑', 'x ∑'), ('…õ', 'e'), ('…£', '…°'), ('…î', 'o')]
        desc[ipa_col] = desc[form_col].apply(on.transcribe).apply(
            i2t).apply(lambda lst: [replace(x, to_rectify) for x in lst])

    else:
        raise ValueError(f'Unrecognized language "{lang}".')
    st.write(desc)

    # Get rid of false complex segments.
    show_all_segs(desc[ipa_col])
    desc[ipa_col] = desc[ipa_col].apply(break_false_complex, lang=lang)
    show_all_segs(desc[ipa_col])

    desc['pgm_ipa'] = desc['gem-pro'].apply(PGmc_ipa_trans).apply(i2t)
    show_all_segs(desc['pgm_ipa'])
    desc['pgm_ipa'] = desc['pgm_ipa'].apply(break_false_complex, lang='pgm')
    show_all_segs(desc['pgm_ipa'])

    src_df = pd.DataFrame()
    src_df['transcription'] = desc['gem-pro']
    src_df['ipa'] = desc['pgm_ipa'].apply(''.join)
    src_df['tokens'] = desc['pgm_ipa'].apply(' '.join)
    src_df['split'] = 'train'
    src_out_path = f'{out_dir}/pgmc-{lang}/pgmc.tsv'
    src_df.to_csv(src_out_path, sep='\t', index=None)
    st.write(f'Source written to {src_out_path}.')

    tgt_df = pd.DataFrame()
    tgt_df['transcription'] = desc[form_col]
    tgt_df['ipa'] = desc[ipa_col].apply(''.join)
    tgt_df['tokens'] = desc[ipa_col].apply(' '.join)
    tgt_df['split'] = 'train'
    tgt_out_path = f'{out_dir}/pgmc-{lang}/{lang}.tsv'
    tgt_df.to_csv(tgt_out_path, sep='\t', index=None)
    st.write(f'Target written to {tgt_out_path}.')
